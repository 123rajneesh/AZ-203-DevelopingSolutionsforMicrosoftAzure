---
lab:
    title: 'Lab: Creating a multi-tier solution by using services in Azure'
    module: 'Module 6: Connect to and consume Azure, and third-party, services'
---

# Lab: Creating a multi-tier solution by using services in Azure
# Student lab manual

## Lab scenario

Your company has successfully adopted and used Microsoft Azure Search in a variety of use cases in your solutions. In your latest solution, your company will store data in an Azure Storage table and will need to index that table by using Azure Search. To accomplish this, you will build an API with minimal code. There are two major requirements for this solution. First, developers who are issuing REST queries should not be aware through any details that Azure Search is being used behind the scenes. Second, developers should be able to add a new record to the table by using a simple REST query. You have decided to use Azure Search, Azure API Management, and Azure Logic Apps to build a minimal-code solution to meet all these requirements.

## Objectives

After you complete this lab, you will be able to:

  - Create an Azure Search account.

  - Manually create an Azure Search index.

  - Create an indexer to automatically parse data from a data source.

  - Create an API Management account.

  - Configure an API as a proxy for another Azure service with header substitution and payload manipulation.

  - Create a Logic Apps resource.

  - Configure a workflow that is triggered by an HTTP request.

## Lab Setup

  - **Estimated time**: 105 minutes

## Instructions

### Before you start

#### Sign in to the lab virtual machine

  - Ensure that you are signed in to your **Windows 10** virtual machine by using the following credentials:
    
      - **Username**: Admin
    
      - **Password**: Pa55w.rd

#### Review installed applications

  - Observe the taskbar located at the bottom of your **Windows 10** desktop. The taskbar contains the icons for the applications that you will use in this lab:
    
      - Microsoft Edge
    
      - File Explorer
    
      - Microsoft Azure Storage Explorer

#### Download the lab files

1.  On the taskbar, select the **Windows PowerShell** icon.

2.  In the PowerShell command prompt, change the current working directory to the **Allfiles (F):\\** path:

    ```
    cd F:
    ```

3.  Within the command prompt, enter the following command and press Enter to Clone the **microsoftlearning/AZ-203-DevelopingSolutionsForAzure** project hosted on GitHub into the **Labfiles** directory:

    ```
    git clone --depth 1 --no-checkout https://github.com/microsoftlearning/AZ-203-DevelopingSolutionsForMicrosoftAzure .
    ```

4.  Within the command prompt, enter the following command and press **Enter** to check out the lab files necessary to complete the **AZ-203.02** lab:

    ```
    git checkout master -- Allfiles/*
    ```

5.  Close the currently running **Windows PowerShell** command prompt application.

### Exercise 1: Creating an Azure Search service in the portal

#### Task 1: Open the Azure portal

1.  Sign in to the [**Azure portal**](https://portal.azure.com) (portal.azure.com).

2.  If this is your first time signing in to the Azure portal, a dialog box will display offering a tour of the portal. Select **Get Started** to skip the tour.

#### Task 2: Create Azure Search account

1.  Create a new **Azure Search** instance with the following details:
    
      - **URL**: prodsearch*\[your name in lowercase\]*
    
      - **New Resource group**: MultiTierService
    
      - **Location**: East US
    
      - **Pricing tier**: Basic

> > **Note**: Wait for Azure to finish creating the Azure Search account before you move forward with the lab. You will receive a notification when the Azure Search account is created.

2.  Access the **Keys** blade of your newly created **Azure Search** instance.

3.  Record one of the **Search Keys**. You will use this value later in the lab.

#### Task 3: Create an index

1.  Access the **prodsearch\*** Search service that you created earlier in this lab.

2.  In the **Search Service** blade, select **Add index**.

3.  Create a new index with the following details:
    
      - **Index name**: retail
    
      - **Key**: id

4.  Configure the index’s fields by using the table below:

| **Field**        | **Type**   | **Retrievable** | **Filterable** | **Sortable** | **Facetable** | **Searchable** | **Analyzer**          |
| ---------------- | ---------- | --------------- | -------------- | ------------ | ------------- | -------------- | --------------------- |
| **id**           | Edm.String | **✓**           |                | **✓**        |               |                |                       |
| **name**         | Edm.String | **✓**           |                | **✓**        |               | **✓**          | **Standard - Lucene** |
| **price**        | Edm.Double | **✓**           | **✓**          | **✓**        | **✓**         |                |                       |
| **quantity**     | Edm.Int32  | **✓**           | **✓**          | **✓**        | **✓**         |                |                       |
| **manufacturer** | Edm.String | **✓**           | **✓**          | **✓**        | **✓**         |                |                       |

#### Review

In this exercise, you created a new Azure Storage account and built an index within the account.

### Exercise 2: Index an Azure Storage table in Azure Search

#### Task 1: Create an Azure Storage account

1.  In the Azure portal, create a new **storage account** with the following details:
    
      - **Existing** **resource** **group**: MultiTierService
    
      - **Name**: prodstorage*\[your name in lowercase\]*
    
      - **Location**: East US
    
      - **Performance**: Standard
    
      - **Account** **kind**: StorageV2 (general purpose v2)
    
      - **Replication**: Read-access geo-redundant storage (RA-GRS)
    
      - **Access** **tier**: Hot

> > **Note**: Wait for Azure to finish creating the Storage account before you move forward with the lab. You will receive a notification when the account is created.

2.  Access the **Access Keys** blade of your newly created **storage account** instance.

3.  Record the value of the **Connection string** field. You will use this value later in this lab.

#### Task 2: Upload table entities to Azure Storage

1.  Access the **prodstorage\*** Storage account that you created earlier in this lab.

2.  In the **Tables service** section, select the **Tables** link.

3.  Create a new **Table** with the following setting:
    
      - **Name**: products

4.  In the **Overview** section of the blade, select **Open in Explorer** to open the Storage account by using the **Azure Storage Explorer.**

5.  In the **Azure Storage Explorer** application that appears, in the **prodstorage\*** Storage account that you created earlier in this lab, locate and open the **products** table.

6.  In the **Products Table** tab, select **Import** and import the **products.csv** file located in the **Allfiles (F):\\Labfiles\\Starter** folder on your lab machine.

#### Task 3: Create an Azure Search indexer

1.  Access the **prodsearch\*** Search service that you created earlier in this lab.

2.  In the **Search Service** blade, select **Import Data**.

3.  In the **Import Data** blade, create a new indexer with the following details:
    
      - **Data Source**: Azure Table Storage
    
      - **Data Source Name**: tabledatasource
    
      - **Connection string**: \<*select the **prodstorage\*** storage account you created earlier in this lab\>*
    
      - **Table name**: products
    
      - **Index name**: products
    
      - **Key**: RowKey
    
      - Configure the index’s fields by using the table below:

| **Field**    | **Type**   | **Retrievable** | **Filterable** | **Sortable** | **Facetable** | **Searchable** | **Analyzer**          |
| ------------ | ---------- | --------------- | -------------- | ------------ | ------------- | -------------- | --------------------- |
| **Key**      | Edm.String | **✓**           |                | **✓**        |               |                |                       |
| **name**     | Edm.String | **✓**           |                | **✓**        |               | **✓**          | **Standard - Lucene** |
| **price**    | Edm.Double | **✓**           | **✓**          | **✓**        | **✓**         |                |                       |
| **quantity** | Edm.Int32  | **✓**           | **✓**          | **✓**        | **✓**         |                |                       |

  - **Indexer** **Name**: tableindexer

  - **Schedule**: Custom

  - **Interval**: 5

<!-- end list -->

4.  Manually **run** the **tableindexer** indexer that you just created in this lab.

5.  Observe the metadata of the **tableindexer** indexer and its latest run. The metadata includes information such as the document count and the status of the last indexing operation. You will observe that the last indexing operation was successful and resulted in multiple documents being added to the index.

#### Task 4: Validate the indexed table data

1.  Open the **Search Explorer** for the **prodsearch\*** Search service that you created earlier in this lab.

2.  Execute the empty query by leaving all fields set to their default (empty) values and selecting **Enter**. Observe that the results of this query returns a page of results for all documents in the index.

3.  Execute the following query and observe the results:

<!-- end list -->

    search=seat

4.  Execute the following query and observe the results:

<!-- end list -->

    $filter=price lt 100

5.  Execute the following query and observe the results:

<!-- end list -->

    facet=quantity,interval:25

6.  Execute the following query and observe the results:

<!-- end list -->

    $filter=quantity gt 25&facet=price,values:100|1000|10000

#### Task 5: Retrieve your Azure Search base URL

1.  Access the **prodsearch\*** Search service that you created earlier in this lab.

2.  In the **Search Service** blade, copy the value of the **URL** field. You will use this value later in the lab.

#### Review

In this exercise, you created an Azure Storage account and indexed a Storage table within the account using Azure Search. After the table was indexed, you were able to issue search queries against a copy of the entities in the Storage table.

### Exercise 3: Build an API proxy tier by using Azure API Management

#### Task 1: Create an API Management resource

> In the Azure portal, create a new **API Management account** with the following details:

  - **Existing** **resource** **group**: MultiTierService

  - **Name**: prodapi*\[your name in lowercase\]*

  - **Location**: East US

  - **Organization name**: Contoso

  - **Pricing** **tier**: Developer (No SLA)

> > **Note**: Wait for Azure to finish creating the API Management account before you move forward with this lab. You will receive a notification when the account is created. It usually takes between 20 and 30 minutes to create an API Management service.

#### Task 2: Define a new API

1.  Access the **prodapi\*** API Management account that you created earlier in this lab.

2.  View the list of **APIs** for the new account.

> > **Note**: All new accounts start with a simple **Echo API**.

3.  Create a new **Blank API** with the following details:
    
      - **Display name**: Search API
    
      - **Name**: search-api
    
      - **Web service URL**: Enter the **Search Service URL** that you copied earlier in this lab. Append the value of the **Web service URL** field with the following relative URL:

> 
> 
>     /indexes/products/docs
> 
> > **Note**: For example, if your web service URL is https://prodsearchstudent.search.windows.net, then your new URL will be https://prodsearchstudent.search.windows.net/indexes/products/docs.

  - **API URL suffix**: search

  - **Products**: Select both the **Starter** and **Unlimited** options.

<!-- end list -->

4.  Add a new operation to the recently created API with the following details:
    
      - **Display name**: List All Documents
    
      - **Name**: list-all-documents
    
      - **URL**: GET /

> Then, select **Save**.

5.  Add a new **Set Headers** inbound policy to **All Operations** with the following details:
    
      - **Name**: api-key
    
      - **Value**: Enter the value for the Search Service Key that you recorded earlier in this lab.

6.  Add a new **Set Query Parameters** inbound policy to **All Operations** with the following details:
    
      - **Name**: api-version
    
      - **Value**: 2017-11-11
    
      - **Action**: override

7.  Add a new **Set Query Parameters** inbound policy scoped to the **List All Documents** operation with the following details:
    
      - **Name**: search
    
      - **Value**: *\**
    
      - **Action**: override

8.  Test the **List All Documents** operation in the **Search API**, observing the results of the API request.

> > **Note**: Observe how there is a large amount of Azure Search metadata in the response. You might not want API users to observe implementation details that occur behind the scenes. In the next task, you will obfuscate much of this data.

#### Task 3: Manipulate an API response

1.  Add a new **Set Headers** inbound policy to **All Operations** with the following details:
    
    1.  **Name**: preference-applied
    
    2.  **Action**: delete

2.  Add a new **Set Headers** inbound policy to **All Operations** with the following details:
    
    3.  **Name**: odata-version
    
    4.  **Action**: delete

3.  Add a new **Set Headers** inbound policy to **All Operations** with the following details:
    
    5.  **Name**: powered-by
    
    6.  **Value**: Contoso
    
    7.  **Action**: override

<!-- end list -->

4.  Add a new custom outbound policy scoped to the **List All Documents** operation by first locating the following block of XML content:

<!-- end list -->

    <outbound>
        <base />
    </outbound>

And then replacing that block of XML with the following XML:

    <outbound>
        <base />
        <set-body>
        @{ 
            var response = context.Response.Body.As<JObject>();
            return response.Property("value").Value.ToString();
        }
        </set-body>
    </outbound>

5.  Test the **List All Documents** operation in the **Search API** observing the results of the API request.

> > **Note**: You will observe that the **preference-applied** and **odata-version** headers you specified have been deleted and replaced with a new **powered-by** header. You will also notice that the response doesn’t contain context data about the OData response, but instead contains a flattened JSON array as the response body.

#### Review

In this exercise, you built a proxy tier between your Azure Search account and any developers who wish to make search queries.

### Exercise 4: Create new table entities by using Azure Logic Apps

#### Task 1: Create a Logic Apps resource

  - In the Azure portal, create a new **logic app** with the following details:
    
      - **Existing** **resource** **group**: MultiTierService
    
      - **Name**: prodworkflow*\[your name in lowercase\]*
    
      - **Location**: East US
    
      - **Log Analytics**: Off

> > **Note**: Wait for Azure to finish creating the Logic Apps resource prior to moving forward with the lab. You will receive a notification when the resource is created.

#### Task 2: Create a trigger for Logic Apps workflow

1.  In the **Logic Apps Designer** blade, select the **Blank Logic App** template.

2.  In the **Designer** area, add a new **When a HTTP request is received** trigger by using the following sample JSON document to generate the JSON schema:

<!-- end list -->

    { 
        "id": "",
        "manufacturer": "",
        "price": 0.00,
        "quantity": 0,
        "name": ""
    }

#### Task 3: Build a connector for Azure Storage

  - In the **Designer** area, add a new “**Insert or Replace Entity”** action with the following details:
    
      - **Connection Name**: tableconnection
    
      - **Storage Account**: \<Select the **prodstorage\*** storage account you created earlier in this lab\>
    
      - **Table**: products
    
      - **Partition Key**: manufacturer (Dynamic Field - When a HTTP request is received)
    
      - **Row Key**: id (Dynamic Field - When a HTTP request is received)
    
      - **Entity**: Body (Dynamic Field - When a HTTP request is received)

#### Task 4: Build a HTTP response action

  - In the **Designer** area, add a new **Response Action** with the following details:
    
    1.  **Status Code**: 201
    
    2.  **Body**: Body (Dynamic Field - Insert or Replace Entity)

#### Task 5: Retrieve a HTTP trigger POST URL

1.  In the **Designer** area, Select **Save**.

2.  After the workflow is saved, the **HTTP POST URL** field in the **When a HTTP request is received** trigger will be updated with a new URL that you’ll need to start this workflow. Copy the URL in the **HTTP POST URL** field. You will use this URL later in the lab.

> > **Note**: This is a very long URL because it includes the URL with the SAS token. Make sure that you copy the entire URL.

#### Task 6: Validate that logic app results are indexed

1.  Open a new Azure Cloud Shell instance.

2.  If the Cloud Shell is not already configured, configure the shell for Bash by using default settings.

3.  Within the Cloud Shell command prompt, enter the following partial **CURL** command to issue a **HTTP POST** request to the Logic Apps instance, and then press Enter:

<!-- end list -->

    curl \
    --header "Content-Type: application/json" \
    --data '{"id":"6","manufacturer":"VEHTOP","price":750,"quantity":6,"name":"car roof rack"}' \

4.  Next, enter the logic app*’s* **HTTP POST URL** you copied earlier in this lab, ensuring that you place the URL within **quotation marks** so that the URL characters are not escaped. Press **Enter** to execute the command.

> > **Note**: For example, if the URL is https://prod.eastus.logic.azure.com:443/workflows/test/triggers/invoke?api-version=2016\&sig=3, then you would insert “https://prod.eastus.logic.azure.com:443/workflows/test/triggers/manual?invoke?api-version=2016\&sig=3”. If you do not include the quotation marks, you will get an error message indicating that the SAS token has been truncated and is required to issue the request. This occurs because the query string separator, **&**, is truncated if it is not enclosed in quotation marks.

5.  Access the **prodsearch\*** Search service that you created earlier in this lab.

6.  Manually **run** the **tableindexer** indexer that you just created in this lab.

7.  Open the **Search Explorer** for the **prodsearch\*** Search service that you created earlier in this lab.

8.  Execute the empty query and observe the results.

> > **Note**: At this point, you will notice a sixth document in your index representing the new document that was inserted by the logic app.

7.  Access the **prodapi\*** API Management account that you created earlier in this lab.

8.  Test the **List All Documents** operation in the **Search API**, observing the results of the API request.

> > **Note**: Observe that there are six documents now instead of five.

#### Review

In this exercise, you created a logic app that takes a HTTP request and then persists the JSON body of the request as a new Azure Storage table entity.

### Exercise 5: Clean up subscription 

#### Task 1: Open Cloud Shell

1.  At the top of the portal, select the **Cloud Shell** icon to open a new shell instance.

2.  At the bottom of the portal, in the **Cloud Shell** command prompt, type the following command and press Enter to list all resource groups in the subscription:

<!-- end list -->

    az group list

3.  Type the following command and press Enter to view a list of possible commands to delete a resource group:

<!-- end list -->

    az group delete --help

#### Task 2: Delete resource groups

1.  Type the following command and press Enter to delete the **MultiTierService** resource group:

<!-- end list -->

    az group delete --name MultiTierService --no-wait --yes

2.  Close the **Cloud Shell** pane at the bottom of the portal.

#### Task 3: Close active applications

1.  Close the currently running **Microsoft Edge** application.

2.  Close the currently running **Microsoft Azure Storage Explorer** application.

#### Review

In this exercise, you cleaned up your subscription by removing the **resource groups** used in this lab.
